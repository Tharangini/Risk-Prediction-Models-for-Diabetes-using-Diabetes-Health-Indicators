{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-12-22T15:42:08.733621Z",
     "iopub.status.busy": "2021-12-22T15:42:08.733259Z",
     "iopub.status.idle": "2021-12-22T15:42:10.356304Z",
     "shell.execute_reply": "2021-12-22T15:42:10.355656Z",
     "shell.execute_reply.started": "2021-12-22T15:42:08.733513Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import chisquare\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "import imblearn\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T15:42:10.358166Z",
     "iopub.status.busy": "2021-12-22T15:42:10.357791Z",
     "iopub.status.idle": "2021-12-22T15:42:11.292662Z",
     "shell.execute_reply": "2021-12-22T15:42:11.291805Z",
     "shell.execute_reply.started": "2021-12-22T15:42:10.358130Z"
    }
   },
   "outputs": [],
   "source": [
    "#Reading the data from kaggle local storage\n",
    "df = pd.read_csv(\"/kaggle/input/diabetes-health-indicators-dataset/diabetes_binary_health_indicators_BRFSS2015.csv\")\n",
    "print(df.columns)\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T15:42:11.294028Z",
     "iopub.status.busy": "2021-12-22T15:42:11.293804Z",
     "iopub.status.idle": "2021-12-22T15:42:11.316883Z",
     "shell.execute_reply": "2021-12-22T15:42:11.316146Z",
     "shell.execute_reply.started": "2021-12-22T15:42:11.294001Z"
    }
   },
   "outputs": [],
   "source": [
    "# Checking for the presence of nulls\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T15:42:11.318345Z",
     "iopub.status.busy": "2021-12-22T15:42:11.317977Z",
     "iopub.status.idle": "2021-12-22T15:42:11.375313Z",
     "shell.execute_reply": "2021-12-22T15:42:11.374302Z",
     "shell.execute_reply.started": "2021-12-22T15:42:11.318313Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predict Columns and the Target columns bifurcation\n",
    "target = 'Diabetes_binary'\n",
    "feats = [col for col in df.columns if col!=target]\n",
    "\n",
    "X = df[feats]\n",
    "y=df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T15:42:11.378618Z",
     "iopub.status.busy": "2021-12-22T15:42:11.377905Z",
     "iopub.status.idle": "2021-12-22T15:42:12.357317Z",
     "shell.execute_reply": "2021-12-22T15:42:12.356664Z",
     "shell.execute_reply.started": "2021-12-22T15:42:11.378559Z"
    }
   },
   "outputs": [],
   "source": [
    "# Number of unique values in each column! All the columns expect BMI are discrete whereas BMI is an approximation\n",
    "col_types = {}\n",
    "for col in df.columns:\n",
    "    if(col != target):\n",
    "        col_types[col] = df.groupby([col]).count()[target].shape[0]\n",
    "print(col_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T15:42:12.358675Z",
     "iopub.status.busy": "2021-12-22T15:42:12.358349Z",
     "iopub.status.idle": "2021-12-22T15:42:47.711143Z",
     "shell.execute_reply": "2021-12-22T15:42:47.710194Z",
     "shell.execute_reply.started": "2021-12-22T15:42:12.358648Z"
    }
   },
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(11,2,figsize = (30,50))\n",
    "i=0\n",
    "row = 0\n",
    "col = 0\n",
    "for col in df.columns:\n",
    "    if(col!=target):\n",
    "        \n",
    "        r = int(i/2)\n",
    "        c = i % 2\n",
    "        if(col_types[col]>2):\n",
    "            sns.scatterplot(df[target],df[col],ax=ax[r][c])\n",
    "        if(col_types[col]<=2):\n",
    "            sns.barplot(df[target],df[col],ax=ax[r][c])\n",
    "        i=i+1\n",
    "            \n",
    "plt.show()           \n",
    "print('The disparity in the heights of bars indicate the dependence between of the target and predictor variables.Higher the disparity higher the importance of the feature') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Dependence\n",
    "Since most of the columns are categorical it is not advisable to use corelation to eliminate any features and hence we are resorting to Chi-Square test ; Mutual Information Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T15:42:47.713759Z",
     "iopub.status.busy": "2021-12-22T15:42:47.712618Z",
     "iopub.status.idle": "2021-12-22T15:42:48.130103Z",
     "shell.execute_reply": "2021-12-22T15:42:48.129248Z",
     "shell.execute_reply.started": "2021-12-22T15:42:47.713702Z"
    }
   },
   "outputs": [],
   "source": [
    "# HighCol, Stroke,HeartDiseaseorAttack seem to be dependent intuitively\n",
    "# Performing Chi-Square test\n",
    "def chi2_independence(col1,col2):\n",
    "    vals = X.groupby([col1,col2]).count()['BMI'].values\n",
    "    X.groupby([col1,col2]).count()['BMI']\n",
    "    col1_p0 = X[X[col1]==0].shape[0]/X.shape[0]\n",
    "    col2_p0 = X[X[col2]==0].shape[0]/X.shape[0]\n",
    "    exp =  [X.shape[0] *col1_p0*col2_p0,X.shape[0] *col1_p0*(1-col2_p0),X.shape[0] *(1-col1_p0)*col2_p0,X.shape[0] *(1-col1_p0)*(1-col2_p0)]\n",
    "    return stats.chisquare(vals,exp).pvalue\n",
    "\n",
    "p1 = chi2_independence('Stroke','HeartDiseaseorAttack')\n",
    "print(p1)\n",
    "p1 = chi2_independence('Stroke','HighChol')\n",
    "print(p1)\n",
    "p1 = chi2_independence('HighBP','HighChol')\n",
    "print(p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T15:42:48.131731Z",
     "iopub.status.busy": "2021-12-22T15:42:48.131366Z",
     "iopub.status.idle": "2021-12-22T15:42:48.564788Z",
     "shell.execute_reply": "2021-12-22T15:42:48.563548Z",
     "shell.execute_reply.started": "2021-12-22T15:42:48.131698Z"
    }
   },
   "outputs": [],
   "source": [
    "# Mutual Information Score\n",
    "print(normalized_mutual_info_score(X['Stroke'],X['HeartDiseaseorAttack'] ))\n",
    "print(normalized_mutual_info_score(X['Stroke'],X['HighChol'] ))\n",
    "print(normalized_mutual_info_score(X['HighBP'],X['HighChol'] ))\n",
    "print(normalized_mutual_info_score(X['PhysActivity'],X['HighChol'] ))\n",
    "print(normalized_mutual_info_score(X['PhysActivity'],X['HighChol'] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T15:42:48.566534Z",
     "iopub.status.busy": "2021-12-22T15:42:48.566257Z",
     "iopub.status.idle": "2021-12-22T15:42:49.286805Z",
     "shell.execute_reply": "2021-12-22T15:42:49.285823Z",
     "shell.execute_reply.started": "2021-12-22T15:42:48.566503Z"
    }
   },
   "outputs": [],
   "source": [
    "print(X.corr().unstack().sort_values().drop_duplicates().head(5))\n",
    "print(X.corr().unstack().sort_values(ascending=False).drop_duplicates().head(5))\n",
    "print('Columns are not heavily linearly correlated. So cant use this to filter out any!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis Testing\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Q1** - CDC has a simple [form](https://www.cdc.gov/prediabetes/takethetest/) to help a candidate understand whether he/she is diabetic. If the candidate is \"safe\" with respect to the select features the result is that the candidate is not diabetic. We want to validate this hypothesis using the data we have\n",
    "#### **Assumptions**: Obviously this wouldnt be 100% accurate but with an alpha of 1-2% would this be accurate?\n",
    "\n",
    "#### **Steps**\n",
    "1. Choose the hypothesis test\n",
    "2. Data Preparation\n",
    "3. Perform the test\n",
    "4. Conclude\n",
    "5. Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T15:42:49.288430Z",
     "iopub.status.busy": "2021-12-22T15:42:49.288129Z",
     "iopub.status.idle": "2021-12-22T15:42:49.336275Z",
     "shell.execute_reply": "2021-12-22T15:42:49.335405Z",
     "shell.execute_reply.started": "2021-12-22T15:42:49.288398Z"
    }
   },
   "outputs": [],
   "source": [
    "# Preparing the data for hypothesis testing - Making them all booleans\n",
    "ht_columns = ['Age','GenHlth','PhysActivity','BMI','Smoker']\n",
    "ht = X[ht_columns]\n",
    "\n",
    "ht['Age'] = (ht['Age']>4).astype('int')\n",
    "ht['GenHlth'] = (ht['GenHlth']<3).astype('int')\n",
    "ht['BMI'] = ((ht['BMI']<=25) & (ht['BMI']>=18)).astype('int')\n",
    "ht['Sum']=ht.sum(axis=1)\n",
    "ht['target']= y\n",
    "ht.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T15:42:49.338559Z",
     "iopub.status.busy": "2021-12-22T15:42:49.338320Z",
     "iopub.status.idle": "2021-12-22T15:42:49.367059Z",
     "shell.execute_reply": "2021-12-22T15:42:49.366157Z",
     "shell.execute_reply.started": "2021-12-22T15:42:49.338520Z"
    }
   },
   "outputs": [],
   "source": [
    "#\"Sum\" column being 0 represents that we are in the \"safe-zone\" with respect to all the features picked by CDC\n",
    "ht['safe_feat'] = (ht['Sum']<1).astype('int')\n",
    "freq_obs = [ht[(ht['safe_feat']==1) & (ht['target']==1)].shape[0],ht[(ht['safe_feat']==1) & (ht['target']==0)].shape[0]]\n",
    "#Because the expected is that \"safe-zone\" is free of diabetes\n",
    "#Instead of using \"0\" in the expected as formulas might have issues we take it as 10\n",
    "freq_exp = [10,sum(freq_obs)-10]\n",
    "\n",
    "chisquare(freq_obs).pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T15:42:49.368866Z",
     "iopub.status.busy": "2021-12-22T15:42:49.368224Z",
     "iopub.status.idle": "2021-12-22T15:42:49.373712Z",
     "shell.execute_reply": "2021-12-22T15:42:49.372828Z",
     "shell.execute_reply.started": "2021-12-22T15:42:49.368831Z"
    }
   },
   "outputs": [],
   "source": [
    "print(freq_obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Conclusion\n",
    "pValue is quite low. So we can reject the null hypothesis and conclude that there is a significant impact "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2 - Does it make sense to have different models for younger individuals vs older individuals?\n",
    "1. Splitting around the age of 40 years let us check this.\n",
    "2. Build different models for the datasets\n",
    "3. Compare feature importances in the resultant models using paired t-test\n",
    "(If the feature importances differ for younger and older individuals we need different models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T15:42:49.375537Z",
     "iopub.status.busy": "2021-12-22T15:42:49.374957Z",
     "iopub.status.idle": "2021-12-22T15:42:51.592442Z",
     "shell.execute_reply": "2021-12-22T15:42:51.591487Z",
     "shell.execute_reply.started": "2021-12-22T15:42:49.375493Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "clf_young = DecisionTreeClassifier(random_state=0)\n",
    "clf_old = DecisionTreeClassifier(random_state=0)\n",
    "col_name = 'Age'\n",
    "cur_feats = [col for col in feats if col!=col_name]\n",
    "#Data split to build two different models\n",
    "X_young = X[X[col_name]<=4][cur_feats]\n",
    "y_young = y[X[col_name]<=4]\n",
    "X_old = X[X[col_name]>4][cur_feats]\n",
    "y_old = y[X[col_name]>4]\n",
    "#Data Frame with feature importance results\n",
    "model_diff=pd.DataFrame()\n",
    "\n",
    "fig,ax=plt.subplots(1,2,figsize=(30,10))\n",
    "#Model for younger\n",
    "clf_young.fit(X_young,y_young)\n",
    "feat_imp_young=pd.Series(clf_young.feature_importances_)\n",
    "model_diff['young'] = feat_imp_young\n",
    "feat_imp_young.index=cur_feats\n",
    "feat_imp_young = feat_imp_young.sort_values(ascending=False)\n",
    "#Plotting feature importances\n",
    "sns.barplot(y=feat_imp_young.index,x=feat_imp_young,ax=ax[0])\n",
    "\n",
    "#Model for older\n",
    "clf_old.fit(X_old,y_old)\n",
    "feat_imp_old=pd.Series(clf_old.feature_importances_)\n",
    "model_diff['old'] = feat_imp_old\n",
    "feat_imp_old.index=cur_feats\n",
    "feat_imp_old = feat_imp_old.sort_values(ascending=False)\n",
    "#plotting feat importances\n",
    "sns.barplot(y=feat_imp_old.index,x=feat_imp_old,ax=ax[1])\n",
    "\n",
    "model_diff.index=cur_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T15:42:51.595787Z",
     "iopub.status.busy": "2021-12-22T15:42:51.595496Z",
     "iopub.status.idle": "2021-12-22T15:42:51.604890Z",
     "shell.execute_reply": "2021-12-22T15:42:51.603916Z",
     "shell.execute_reply.started": "2021-12-22T15:42:51.595756Z"
    }
   },
   "outputs": [],
   "source": [
    "stats.ttest_rel(model_diff['young'], model_diff['old'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Conclusion:\n",
    "p Value is very high and hence we know that the models are not very different and hence we do not need to split and build different for younger and older individuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-19T18:55:26.378047Z",
     "iopub.status.busy": "2021-12-19T18:55:26.377259Z",
     "iopub.status.idle": "2021-12-19T18:55:26.384071Z",
     "shell.execute_reply": "2021-12-19T18:55:26.382926Z",
     "shell.execute_reply.started": "2021-12-19T18:55:26.378009Z"
    }
   },
   "source": [
    "### Q3 - Does it make sense to have different models for female individuals vs male individuals?\n",
    "1. Splitting the data for male and female.\n",
    "2. Build different models for the datasets\n",
    "3. Compare feature importances in the resultant models using paired t-test\n",
    "(If the feature importances differ for female and male individuals we need different models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T15:42:51.606354Z",
     "iopub.status.busy": "2021-12-22T15:42:51.606138Z",
     "iopub.status.idle": "2021-12-22T15:42:53.653171Z",
     "shell.execute_reply": "2021-12-22T15:42:53.652342Z",
     "shell.execute_reply.started": "2021-12-22T15:42:51.606329Z"
    }
   },
   "outputs": [],
   "source": [
    "clf_male = DecisionTreeClassifier(random_state=0)\n",
    "clf_female = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "#Data split to build two different models\n",
    "col_name = 'Sex'\n",
    "cur_feats = [col for col in feats if col!=col_name]\n",
    "X_female = X[X[col_name]==0][cur_feats]\n",
    "y_female = y[X[col_name]==0]\n",
    "X_male = X[X[col_name]==1][cur_feats]\n",
    "y_male = y[X[col_name]==1]\n",
    "#Data Frame with feature importance results\n",
    "model_diff=pd.DataFrame()\n",
    "\n",
    "fig,ax=plt.subplots(1,2,figsize=(30,10))\n",
    "#Model for female\n",
    "clf_female.fit(X_female,y_female)\n",
    "feat_imp_female=pd.Series(clf_female.feature_importances_)\n",
    "model_diff['female'] = feat_imp_female\n",
    "feat_imp_female.index=cur_feats\n",
    "feat_imp_female = feat_imp_female.sort_values(ascending=False)\n",
    "#Plotting feature importances\n",
    "sns.barplot(y=feat_imp_female.index,x=feat_imp_female,ax=ax[0])\n",
    "\n",
    "#Model for male\n",
    "clf_male.fit(X_male,y_male)\n",
    "feat_imp_male=pd.Series(clf_male.feature_importances_)\n",
    "model_diff['male'] = feat_imp_male\n",
    "feat_imp_male.index=cur_feats\n",
    "feat_imp_male = feat_imp_male.sort_values(ascending=False)\n",
    "#plotting feat importances\n",
    "sns.barplot(y=feat_imp_male.index,x=feat_imp_male,ax=ax[1])\n",
    "\n",
    "model_diff.index=cur_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T15:42:53.655031Z",
     "iopub.status.busy": "2021-12-22T15:42:53.654605Z",
     "iopub.status.idle": "2021-12-22T15:42:53.661669Z",
     "shell.execute_reply": "2021-12-22T15:42:53.660825Z",
     "shell.execute_reply.started": "2021-12-22T15:42:53.654978Z"
    }
   },
   "outputs": [],
   "source": [
    "stats.ttest_rel(model_diff['female'], model_diff['male'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4 - Does it make sense to have different models for Smoker individuals vs Non-Smoker individuals?\n",
    "1. Splitting the data for male and female.\n",
    "2. Build different models for the datasets\n",
    "3. Compare feature importances in the resultant models using paired t-test\n",
    "(If the feature importances differ for female and male individuals we need different models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T15:42:53.663503Z",
     "iopub.status.busy": "2021-12-22T15:42:53.663286Z",
     "iopub.status.idle": "2021-12-22T15:42:55.849474Z",
     "shell.execute_reply": "2021-12-22T15:42:55.848511Z",
     "shell.execute_reply.started": "2021-12-22T15:42:53.663478Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "clf_male = DecisionTreeClassifier(random_state=0)\n",
    "clf_female = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "#Data split to build two different models\n",
    "col_name = 'Smoker'\n",
    "cur_feats = [col for col in feats if col!=col_name]\n",
    "X_female = X[X[col_name]==0][cur_feats]\n",
    "y_female = y[X[col_name]==0]\n",
    "X_male = X[X[col_name]==1][cur_feats]\n",
    "y_male = y[X[col_name]==1]\n",
    "#Data Frame with feature importance results\n",
    "model_diff=pd.DataFrame()\n",
    "\n",
    "fig,ax=plt.subplots(1,2,figsize=(30,10))\n",
    "#Model for female\n",
    "clf_female.fit(X_female,y_female)\n",
    "feat_imp_female=pd.Series(clf_female.feature_importances_)\n",
    "model_diff['non_smoker'] = feat_imp_female\n",
    "feat_imp_female.index=cur_feats\n",
    "feat_imp_female = feat_imp_female.sort_values(ascending=False)\n",
    "#Plotting feature importances\n",
    "sns.barplot(y=feat_imp_female.index,x=feat_imp_female,ax=ax[0])\n",
    "\n",
    "#Model for male\n",
    "clf_male.fit(X_male,y_male)\n",
    "feat_imp_male=pd.Series(clf_male.feature_importances_)\n",
    "model_diff['smoker'] = feat_imp_male\n",
    "feat_imp_male.index=cur_feats\n",
    "feat_imp_male = feat_imp_male.sort_values(ascending=False)\n",
    "#plotting feat importances\n",
    "sns.barplot(y=feat_imp_male.index,x=feat_imp_male,ax=ax[1])\n",
    "\n",
    "model_diff.index=cur_feats\n",
    "\n",
    "stats.ttest_rel(model_diff['non_smoker'], model_diff['smoker'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T15:42:55.850938Z",
     "iopub.status.busy": "2021-12-22T15:42:55.850735Z",
     "iopub.status.idle": "2021-12-22T15:42:55.893706Z",
     "shell.execute_reply": "2021-12-22T15:42:55.892652Z",
     "shell.execute_reply.started": "2021-12-22T15:42:55.850914Z"
    }
   },
   "outputs": [],
   "source": [
    "X.groupby(['NoDocbcCost']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5 - Does it make sense to have different models for NoDoctorBcos Of Cost individuals vs No Cost Problem individuals?\n",
    "1. Splitting the data for male and female.\n",
    "2. Build different models for the datasets\n",
    "3. Compare feature importances in the resultant models using paired t-test\n",
    "(If the feature importances differ for female and male individuals we need different models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T15:42:55.895285Z",
     "iopub.status.busy": "2021-12-22T15:42:55.895000Z",
     "iopub.status.idle": "2021-12-22T15:42:58.045452Z",
     "shell.execute_reply": "2021-12-22T15:42:58.044627Z",
     "shell.execute_reply.started": "2021-12-22T15:42:55.895244Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "clf_male = DecisionTreeClassifier(random_state=0)\n",
    "clf_female = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "#Data split to build two different models\n",
    "col_name = 'NoDocbcCost'\n",
    "cur_feats = [col for col in feats if col!=col_name]\n",
    "X_female = X[X[col_name]==0][cur_feats]\n",
    "y_female = y[X[col_name]==0]\n",
    "X_male = X[X[col_name]==1][cur_feats]\n",
    "y_male = y[X[col_name]==1]\n",
    "#Data Frame with feature importance results\n",
    "model_diff=pd.DataFrame()\n",
    "\n",
    "fig,ax=plt.subplots(1,2,figsize=(30,10))\n",
    "#Model for female\n",
    "clf_female.fit(X_female,y_female)\n",
    "feat_imp_female=pd.Series(clf_female.feature_importances_)\n",
    "model_diff['costProb'] = feat_imp_female\n",
    "feat_imp_female.index=cur_feats\n",
    "feat_imp_female = feat_imp_female.sort_values(ascending=False)\n",
    "#Plotting feature importances\n",
    "sns.barplot(y=feat_imp_female.index,x=feat_imp_female,ax=ax[0])\n",
    "\n",
    "#Model for male\n",
    "clf_male.fit(X_male,y_male)\n",
    "feat_imp_male=pd.Series(clf_male.feature_importances_)\n",
    "model_diff['noCostProb'] = feat_imp_male\n",
    "feat_imp_male.index=cur_feats\n",
    "feat_imp_male = feat_imp_male.sort_values(ascending=False)\n",
    "#plotting feat importances\n",
    "sns.barplot(y=feat_imp_male.index,x=feat_imp_male,ax=ax[1])\n",
    "\n",
    "model_diff.index=cur_feats\n",
    "\n",
    "stats.ttest_rel(model_diff['costProb'], model_diff['noCostProb'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "Using Random Forest\n",
    "1. Perform classification with PCA\n",
    "2. Perform calssification without PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T15:42:58.046775Z",
     "iopub.status.busy": "2021-12-22T15:42:58.046532Z",
     "iopub.status.idle": "2021-12-22T15:42:58.235495Z",
     "shell.execute_reply": "2021-12-22T15:42:58.234881Z",
     "shell.execute_reply.started": "2021-12-22T15:42:58.046747Z"
    }
   },
   "outputs": [],
   "source": [
    "#Split into Train and Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "# Split train into train and CV\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(X_train, y_train, test_size=0.33, random_state=42)\n",
    "#Oversample data\n",
    "oversample = RandomOverSampler(sampling_strategy=0.5)\n",
    "X_over, y_over = oversample.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T15:42:58.237138Z",
     "iopub.status.busy": "2021-12-22T15:42:58.236743Z",
     "iopub.status.idle": "2021-12-22T15:42:58.557668Z",
     "shell.execute_reply": "2021-12-22T15:42:58.556665Z",
     "shell.execute_reply.started": "2021-12-22T15:42:58.237109Z"
    }
   },
   "outputs": [],
   "source": [
    "#Scaling Data - Standard Scalar before PCA\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_std = scaler.transform(X_train)\n",
    "X_test_std = scaler.transform(X_test)\n",
    "\n",
    "#Performing PCA where we just pick the features that cover 85% of the variance\n",
    "pca = PCA(n_components=0.85)\n",
    "pca.fit(X_train_std)\n",
    "len(pca.components_)\n",
    "X_train_std_pca = pca.transform(X_train_std)\n",
    "X_test_std_pca = pca.transform(X_test_std)\n",
    "\n",
    "X_over_pca, y_over_pca = oversample.fit_resample(X_train_std_pca, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T15:42:58.559930Z",
     "iopub.status.busy": "2021-12-22T15:42:58.559388Z",
     "iopub.status.idle": "2021-12-22T15:46:16.811935Z",
     "shell.execute_reply": "2021-12-22T15:46:16.811018Z",
     "shell.execute_reply.started": "2021-12-22T15:42:58.559886Z"
    }
   },
   "outputs": [],
   "source": [
    "feat_imp=np.zeros(len(feats))\n",
    "\n",
    "cnt=0\n",
    "for n in range(50,200,50):\n",
    "#     for d in range(5,20,5):\n",
    "            for m in range(40,60,10):\n",
    "                    for m2 in range(10,30,10):\n",
    "                        clf = RandomForestClassifier(n_estimators = n,min_samples_split=m,min_samples_leaf=m2)\n",
    "                        clf.fit(X_over,y_over)\n",
    "                        print(f'Esimators : {n}, min_samples_split : {m},min_samples_leaf: {m2}')\n",
    "                        print(f'CV Score - {f1_score(clf.predict(X_cv),y_cv,average=\"weighted\")}')\n",
    "                        print(f'Train Score - {f1_score(clf.predict(X_train),y_train,average=\"weighted\")}')\n",
    "                        feat_imp = feat_imp+clf.feature_importances_\n",
    "                        cnt=cnt+1\n",
    "feat_imp = feat_imp/cnt\n",
    "feat_imp=pd.Series(feat_imp)\n",
    "\n",
    "#plotting feat importances\n",
    "feat_imp.index=feats\n",
    "feat_imp = feat_imp.sort_values(ascending=False)\n",
    "sns.barplot(y=feat_imp.index,x=feat_imp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Possible Feature Elmination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T15:46:16.813795Z",
     "iopub.status.busy": "2021-12-22T15:46:16.813550Z",
     "iopub.status.idle": "2021-12-22T15:46:17.133882Z",
     "shell.execute_reply": "2021-12-22T15:46:17.133118Z",
     "shell.execute_reply.started": "2021-12-22T15:46:16.813768Z"
    }
   },
   "outputs": [],
   "source": [
    "A = X.copy()\n",
    "A['Food'] = A['Fruits']+A['Veggies']\n",
    "A.drop(columns=['Fruits','Veggies'],inplace=True)\n",
    "A['lifeStyle'] = A['Smoker']+A['HvyAlcoholConsump']\n",
    "A.drop(columns=['Smoker','HvyAlcoholConsump'],inplace=True)\n",
    "A.drop(columns=['CholCheck','NoDocbcCost','AnyHealthcare'],inplace=True)\n",
    "\n",
    "A_train,A_test,Ay_train,Ay_test = train_test_split(A,y,test_size=0.33,random_state=0)\n",
    "A_over, Ay_over = oversample.fit_resample(A_train, Ay_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T15:46:17.135065Z",
     "iopub.status.busy": "2021-12-22T15:46:17.134861Z",
     "iopub.status.idle": "2021-12-22T15:46:17.473115Z",
     "shell.execute_reply": "2021-12-22T15:46:17.472134Z",
     "shell.execute_reply.started": "2021-12-22T15:46:17.135034Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_clf.fit(X_train, y_train)\n",
    "\n",
    "print(f'Test Score - {f1_score(dummy_clf.predict(X_test),y_test)}')\n",
    "print(f'Train Score - {f1_score(dummy_clf.predict(X_train),y_train)}')\n",
    "\n",
    "print(f'Test Score - {accuracy_score(dummy_clf.predict(X_test),y_test)}')\n",
    "print(f'Train Score - {accuracy_score(dummy_clf.predict(X_train),y_train)}')\n",
    "\n",
    "print(f'Test Score - {precision_score(dummy_clf.predict(X_test),y_test)}')\n",
    "print(f'Train Score - {precision_score(dummy_clf.predict(X_train),y_train)}')\n",
    "print(f'Test Score - {recall_score(dummy_clf.predict(X_test),y_test)}')\n",
    "print(f'Train Score - {recall_score(dummy_clf.predict(X_train),y_train)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impact of OverSampling the data for imbalanced classification problems\n",
    "## Impact of PCA on the data like this which is mostly categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T15:46:17.474501Z",
     "iopub.status.busy": "2021-12-22T15:46:17.474222Z",
     "iopub.status.idle": "2021-12-22T15:46:24.949646Z",
     "shell.execute_reply": "2021-12-22T15:46:24.948739Z",
     "shell.execute_reply.started": "2021-12-22T15:46:17.474473Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Logistic Regression Classification')\n",
    "print('--------------------------------------------------------------')\n",
    "#Decision Tree as a model slightly better than baseline\n",
    "print('Imbalanced')\n",
    "clf = LogisticRegression(solver='liblinear')\n",
    "clf.fit(X_train,y_train)\n",
    "print(f'Test Score - {f1_score(clf.predict(X_test),y_test)}')\n",
    "print(f'Train Score - {f1_score(clf.predict(X_train),y_train)}')\n",
    "\n",
    "# Comparing Decision Tree performance on imbalanced data vs Oversampled data\n",
    "print('Oversampled')\n",
    "clf = LogisticRegression(solver='liblinear')\n",
    "clf.fit(X_over,y_over)\n",
    "print(f'Test Score - {f1_score(clf.predict(X_test),y_test)}')\n",
    "print(f'Train Score - {f1_score(clf.predict(X_train),y_train)}')\n",
    "\n",
    "print('PCA and oversampled')\n",
    "clf = LogisticRegression(solver='liblinear')\n",
    "clf.fit(X_over_pca,y_over_pca)\n",
    "print(f'Test Score - {f1_score(clf.predict(X_test_std_pca),y_test)}')\n",
    "print(f'Train Score - {f1_score(clf.predict(X_train_std_pca),y_train)}')\n",
    "\n",
    "print('Feature Selection')\n",
    "clf.fit(A_over,Ay_over)\n",
    "print(f'Test Score - {f1_score(clf.predict(A_test),Ay_test)}')\n",
    "print(f'Train Score - {f1_score(clf.predict(A_over),Ay_over)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T15:46:24.951899Z",
     "iopub.status.busy": "2021-12-22T15:46:24.951107Z",
     "iopub.status.idle": "2021-12-22T15:46:33.255292Z",
     "shell.execute_reply": "2021-12-22T15:46:33.254355Z",
     "shell.execute_reply.started": "2021-12-22T15:46:24.951861Z"
    }
   },
   "outputs": [],
   "source": [
    "print('DecisionTree Classification')\n",
    "print('--------------------------------------------------------------')\n",
    "\n",
    "#Decision Tree as a model slightly better than baseline\n",
    "print('Imbalanced')\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train,y_train)\n",
    "print(f'Test Score - {f1_score(clf.predict(X_test),y_test)}')\n",
    "print(f'Train Score - {f1_score(clf.predict(X_train),y_train)}')\n",
    "\n",
    "#Comparing Decision Tree performance on imbalanced data vs Oversampled data\n",
    "print('Oversampled')\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_over,y_over)\n",
    "print(f'Test Score - {f1_score(clf.predict(X_test),y_test)}')\n",
    "print(f'Train Score - {f1_score(clf.predict(X_train),y_train)}')\n",
    "\n",
    "print('PCA and oversampled')\n",
    "clf.fit(X_over_pca,y_over_pca)\n",
    "print(f'Test Score - {f1_score(clf.predict(X_test_std_pca),y_test)}')\n",
    "print(f'Train Score - {f1_score(clf.predict(X_train_std_pca),y_train)}')\n",
    "\n",
    "print('Feature Selection')\n",
    "clf.fit(A_over,Ay_over)\n",
    "print(f'Test Score - {f1_score(clf.predict(A_test),Ay_test)}')\n",
    "print(f'Train Score - {f1_score(clf.predict(A_over),Ay_over)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T15:46:33.256897Z",
     "iopub.status.busy": "2021-12-22T15:46:33.256604Z",
     "iopub.status.idle": "2021-12-22T15:49:32.042613Z",
     "shell.execute_reply": "2021-12-22T15:49:32.041934Z",
     "shell.execute_reply.started": "2021-12-22T15:46:33.256857Z"
    }
   },
   "outputs": [],
   "source": [
    "print('RandomForestClassification')\n",
    "print('--------------------------------------------------------------')\n",
    "\n",
    "#Is Random Forest in-general performing better\n",
    "print('Imbalanced')\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train,y_train)\n",
    "print(f'Test Score - {f1_score(clf.predict(X_test),y_test)}')\n",
    "print(f'Train Score - {f1_score(clf.predict(X_train),y_train)}')\n",
    "\n",
    "# Is Random Forest in-general performing better\n",
    "print('Oversampled')\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_over,y_over)\n",
    "print(f'Test Score - {f1_score(clf.predict(X_test),y_test)}')\n",
    "print(f'Train Score - {f1_score(clf.predict(X_train),y_train)}')\n",
    "\n",
    "print('PCA and oversampled')\n",
    "clf.fit(X_over_pca,y_over_pca)\n",
    "print(f'Test Score - {f1_score(clf.predict(X_test_std_pca),y_test)}')\n",
    "print(f'Train Score - {f1_score(clf.predict(X_train_std_pca),y_train)}')\n",
    "\n",
    "print('Feature Selection')\n",
    "clf.fit(A_over,Ay_over)\n",
    "print(f'Test Score - {f1_score(clf.predict(A_test),Ay_test)}')\n",
    "print(f'Train Score - {f1_score(clf.predict(A_over),Ay_over)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T15:49:32.044462Z",
     "iopub.status.busy": "2021-12-22T15:49:32.043999Z",
     "iopub.status.idle": "2021-12-22T15:50:26.894899Z",
     "shell.execute_reply": "2021-12-22T15:50:26.894197Z",
     "shell.execute_reply.started": "2021-12-22T15:49:32.044422Z"
    }
   },
   "outputs": [],
   "source": [
    "print('XGBoost Classifier')\n",
    "print('--------------------------------------------------------------')\n",
    "\n",
    "#Is Random Forest in-general performing better\n",
    "print('Imbalanced')\n",
    "model = XGBClassifier(eval_metric='auc',scale_pos_weight = (y_over.shape[0] / y.sum())-1)\n",
    "model.fit(X_over, y_over)\n",
    "print(f'Test Score - {f1_score(model.predict(X_test),y_test)}')\n",
    "print(f'Train Score - {f1_score(model.predict(X_train),y_train)}')\n",
    "\n",
    "print('Oversampled')\n",
    "model = XGBClassifier(eval_metric='auc',scale_pos_weight = (y_over.shape[0] / y.sum())-1)\n",
    "model.fit(X_train, y_train)\n",
    "print(f'Test Score - {f1_score(model.predict(X_test),y_test)}')\n",
    "print(f'Train Score - {f1_score(model.predict(X_train),y_train)}')\n",
    "\n",
    "print('PCA and oversampled')\n",
    "model.fit(X_over_pca,y_over_pca)\n",
    "print(f'Test Score - {f1_score(clf.predict(X_test_std_pca),y_test)}')\n",
    "print(f'Train Score - {f1_score(clf.predict(X_train_std_pca),y_train)}')\n",
    "\n",
    "print('Feature Selection')\n",
    "model.fit(A_over,Ay_over)\n",
    "print(f'Test Score - {f1_score(model.predict(A_test),Ay_test)}')\n",
    "print(f'Train Score - {f1_score(model.predict(A_over),Ay_over)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper Parameter Tuning using Cross Validation data with Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T15:50:26.896795Z",
     "iopub.status.busy": "2021-12-22T15:50:26.896309Z",
     "iopub.status.idle": "2021-12-22T16:02:40.071902Z",
     "shell.execute_reply": "2021-12-22T16:02:40.070663Z",
     "shell.execute_reply.started": "2021-12-22T15:50:26.896762Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cross Validation of Random Forest\n",
    "for n in range(50,200,50):\n",
    "            for m in range(20,60,10):\n",
    "                    for m2 in range(10,50,10):\n",
    "                        clf = RandomForestClassifier(n_estimators = n,min_samples_split=m,min_samples_leaf=m2)\n",
    "                        clf.fit(X_over,y_over)\n",
    "                        print(f'Esimators : {n}, min_samples_split : {m},min_samples_leaf: {m2}')\n",
    "                        print(f'CV Score - {f1_score(clf.predict(X_cv),y_cv,average=\"weighted\")}')\n",
    "                        print(f'Train Score - {f1_score(clf.predict(X_train),y_train,average=\"weighted\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper Parameter Tuning using Cross Validation data with XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T16:02:40.074927Z",
     "iopub.status.busy": "2021-12-22T16:02:40.074528Z",
     "iopub.status.idle": "2021-12-22T16:03:50.941969Z",
     "shell.execute_reply": "2021-12-22T16:03:50.939849Z",
     "shell.execute_reply.started": "2021-12-22T16:02:40.074882Z"
    }
   },
   "outputs": [],
   "source": [
    "# XGBoost Hyper Parameter tuning\n",
    "for ss in range(5,9):\n",
    "        for cs in range(5,9):\n",
    "\n",
    "            model = XGBClassifier(learning_rate =0.1,n_estimators=50,gamma=0,colsample_bytree=(cs/10),subsample=(ss/10),objective= 'binary:logistic',seed=27)\n",
    "            model.fit(X_over,y_over)\n",
    "            print(f'{ss},{cs}')\n",
    "            print(f'Test Score - {f1_score(model.predict(X_test),y_test,average=\"weighted\")}')\n",
    "            print(f'Train Score - {f1_score(model.predict(X_over),y_over,average=\"weighted\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper Parameter Tuning using Cross Validation data with MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T16:03:50.944247Z",
     "iopub.status.busy": "2021-12-22T16:03:50.943599Z",
     "iopub.status.idle": "2021-12-22T16:09:35.621918Z",
     "shell.execute_reply": "2021-12-22T16:09:35.620968Z",
     "shell.execute_reply.started": "2021-12-22T16:03:50.944199Z"
    }
   },
   "outputs": [],
   "source": [
    "# Neural Network Hyper Parameter Tuning\n",
    "for h1 in np.arange(1, 6):\n",
    "     for h2 in np.arange(1, 5):\n",
    "        clf = MLPClassifier(solver='sgd',alpha=1e-05,hidden_layer_sizes=(h1,h2), random_state=1,max_iter=100)\n",
    "        clf.fit(X_train_std, y_train)\n",
    "        print(f'{h1},{h2}')\n",
    "        print(f1_score(clf.predict(X_test_std),y_test,average='weighted'))\n",
    "        print(f1_score(clf.predict(X_train_std),y_train,average='weighted'))\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper Parameter Tuning with 80% of the Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T16:09:35.624479Z",
     "iopub.status.busy": "2021-12-22T16:09:35.623800Z",
     "iopub.status.idle": "2021-12-22T16:09:35.629990Z",
     "shell.execute_reply": "2021-12-22T16:09:35.629108Z",
     "shell.execute_reply.started": "2021-12-22T16:09:35.624430Z"
    }
   },
   "outputs": [],
   "source": [
    "# for n in range(50,200,50):\n",
    "#             for m in range(20,60,10):\n",
    "#                     for m2 in range(10,50,10):\n",
    "#                         clf = RandomForestClassifier(n_estimators = n,min_samples_split=m,min_samples_leaf=m2)\n",
    "#                         clf.fit(A_over,Ay_over)\n",
    "#                         print(f'Esimators : {n}, min_samples_split : {m},min_samples_leaf: {m2}')\n",
    "#                         print(f'CV Score - {f1_score(clf.predict(A_test),Ay_test,average=\"weighted\")}')\n",
    "#                         print(f'Train Score - {f1_score(clf.predict(A_over),Ay_over,average=\"weighted\")}')\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T16:09:35.632593Z",
     "iopub.status.busy": "2021-12-22T16:09:35.631938Z",
     "iopub.status.idle": "2021-12-22T16:09:35.648906Z",
     "shell.execute_reply": "2021-12-22T16:09:35.647942Z",
     "shell.execute_reply.started": "2021-12-22T16:09:35.632541Z"
    }
   },
   "outputs": [],
   "source": [
    "# #XGBoost Hyper Parameter tuning\n",
    "# for ss in range(5,9):\n",
    "#         for cs in range(5,9):\n",
    "\n",
    "#             model = XGBClassifier(learning_rate =0.1,n_estimators=50,gamma=0,colsample_bytree=(cs/10),subsample=(ss/10),objective= 'binary:logistic',seed=27)\n",
    "#             model.fit(A_over,Ay_over)\n",
    "#             print(f'{ss},{cs}')\n",
    "#             print(f'Test Score - {f1_score(model.predict(A_test),Ay_test,average=\"weighted\")}')\n",
    "#             print(f'Train Score - {f1_score(model.predict(A_over),Ay_over,average=\"weighted\")}')\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
